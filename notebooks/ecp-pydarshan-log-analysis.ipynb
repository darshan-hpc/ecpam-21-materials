{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Darshan Analysis\n",
    "\n",
    "Basic Notebook to perform initial analysis of a single log.\n",
    "\n",
    "### Verify Install\n",
    "Verify that importing darshan works.\n",
    "If it throws an exception, probably becaues libdarshan-util.so is not found.\n",
    "You can install this from the darshan repo or search for the library on your system.\n",
    "\n",
    "> export LD_LIBRARY_PATH=<path/to/libdarshan-util.so>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Some other support libraries\n",
    "#\n",
    "import pprint\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point to your logfile\n",
    "- Point `logfile` to your logfile of interest.\n",
    "- Make sure your path is relative to where the notebook is running from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile=\"examples/shane_macsio_id29959_5-22-32552-7035573431850780836_1590156158.darshan\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the DarshanReport\n",
    "This object holds the entire data of the log.\n",
    "\n",
    "*read_all=True* will log the data from all supported records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = darshan.DarshanReport(logfile, read_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Overview and Metadata\n",
    "- Look at the 'Loaded Records' to see how many records are within each module.\n",
    "- Look at the 'Name Records' for the total number of known file records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.info()\n",
    "runtime = report.end_time - report.start_time\n",
    "runtime = runtime.total_seconds()\n",
    "nprocs = report.metadata['job']['nprocs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is I/O significant for your application runtime?\n",
    "- significant is usually >5% or >10%\n",
    "\n",
    "### Average I/O per rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = []\n",
    "slowest = []\n",
    "total_df = None\n",
    "\n",
    "if 'POSIX' in report.modules:\n",
    "    df = report.records['POSIX'].to_df()\n",
    "    posix_df = pandas.merge(df['counters'], df['fcounters'], left_on=['id','rank'], right_on=['id','rank'])\n",
    "    col_list += ['POSIX_F_READ_TIME', 'POSIX_F_WRITE_TIME', 'POSIX_F_META_TIME']\n",
    "    slowest += ['POSIX_F_SLOWEST_RANK_TIME']\n",
    "    \n",
    "if 'MPI-IO' in report.modules:\n",
    "    df = report.records['MPI-IO'].to_df()\n",
    "    mpiio_df = pandas.merge(df['counters'], df['fcounters'], left_on=['id','rank'], right_on=['id','rank'])\n",
    "    col_list += ['MPIIO_F_READ_TIME', 'MPIIO_F_WRITE_TIME', 'MPIIO_F_META_TIME']\n",
    "    slowest += ['MPIIO_F_SLOWEST_RANK_TIME']\n",
    "\n",
    "\n",
    "if 'STDIO' in report.modules:\n",
    "    df = report.records['STDIO'].to_df()\n",
    "    stdio_df = pandas.merge(df['counters'], df['fcounters'], left_on=['id','rank'], right_on=['id','rank'])\n",
    "    col_list += ['STDIO_F_READ_TIME', 'STDIO_F_WRITE_TIME', 'STDIO_F_META_TIME']\n",
    "    slowest += ['STDIO_F_SLOWEST_RANK_TIME']\n",
    "\n",
    "if all(x in report.modules for x in ['POSIX', 'MPI-IO', 'STDIO']):\n",
    "    total_df = pandas.merge(posix_df, mpiio_df, left_on=['id','rank'], right_on=['id','rank'], how='outer')\n",
    "    total_df = pandas.merge(total_df, stdio_df, left_on=['id','rank'], right_on=['id','rank'], how='outer')\n",
    "elif all(x in report.modules for x in ['POSIX', 'MPI-IO']):\n",
    "    total_df = pandas.merge(posix_df, mpiio_df, left_on=['id','rank'], right_on=['id','rank'], how='outer')\n",
    "elif all(x in report.modules for x in ['POSIX', 'STDIO']):\n",
    "    total_df = pandas.merge(posix_df, stdio_df, left_on=['id','rank'], right_on=['id','rank'], how='outer')\n",
    "else:\n",
    "    total_df = posix_df\n",
    "\n",
    "aseries = total_df[col_list].sum(axis=0).divide(runtime*nprocs)\n",
    "print(aseries)\n",
    "aseries.plot.bar(title='Average Rank I/O Ratio',ylabel='Ratio')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slowest Rank I/O\n",
    "Looking at average time per rank can be deceiving if your I/O is imbalanced.\n",
    "- I/O is concentrated on a few ranks\n",
    "- I/O storage problem effected only part of system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtotal_df = total_df.groupby('rank')\n",
    "shared_series = gtotal_df[slowest].sum().divide(runtime).head(n=1)\n",
    "nonshared_series = gtotal_df[col_list].sum().divide(runtime).drop(-1)\n",
    "\n",
    "if shared_series.shape[0] > 0:\n",
    "    print(shared_series)\n",
    "    #print(shared_series.max().max())\n",
    "    pass\n",
    "\n",
    "if nonshared_series.shape[0] > 0:\n",
    "    #print(nonshared_series)\n",
    "    print(nonshared_series.max())\n",
    "    #print(nonshared_series.idxmax())\n",
    "    #print(nonshared_series.shape)\n",
    "    key = nonshared_series.max().idxmax()\n",
    "    idx = nonshared_series.idxmax().get(key)\n",
    "    print(\"rank = \", idx)\n",
    "\n",
    "title='Worst Rank I/O Ratio'\n",
    "ylabel='Ratio'\n",
    "if shared_series.shape[0] > 0 and nonshared_series.shape[0] > 0:\n",
    "    worst = nonshared_series + shared_series.max().max()\n",
    "    worst.loc[idx].plot.bar(title=title,ylabel=ylabel)\n",
    "elif shared_series.shape[0] > 0:\n",
    "    worst = shared_series\n",
    "    worst.plot.bar(title=title,ylabel=ylabel)\n",
    "else:\n",
    "    worst = nonshared_series\n",
    "    worst.loc[idx].plot.bar(title=title,ylabel=ylabel)\n",
    "\n",
    "#print(worst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Filesystem are your Using?\n",
    "- most HPC systems have a dedicated high speed storage system, make sure you're using it.\n",
    "- It's likely not you're home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.loc[:,'mount'] = 'Unknown'\n",
    "total_df.loc[:,'mtype'] = 'Unknown'\n",
    "for index, row in total_df.iterrows():\n",
    "    for m in report.mounts:\n",
    "        if report.name_records[row['id']].startswith(m[0]):\n",
    "            total_df.at[index, 'mount'] = m[0]\n",
    "            total_df.at[index, 'mtype'] = m[1]\n",
    "            break\n",
    "gtotal_df = total_df.groupby('mount')\n",
    "posix_list = ['POSIX_BYTES_READ', 'POSIX_BYTES_WRITTEN']\n",
    "stdio_list = ['STDIO_BYTES_READ', 'STDIO_BYTES_WRITTEN']\n",
    "mpiio_list = ['MPIIO_BYTES_READ', 'MPIIO_BYTES_WRITTEN']\n",
    "col_list = ['mtype']\n",
    "if 'POSIX' in report.modules:\n",
    "    col_list += posix_list\n",
    "if 'STDIO' in report.modules:\n",
    "    col_list += stdio_list\n",
    "if 'MPI-IO' in report.modules:\n",
    "    col_list += mpiio_list\n",
    "print(\"\\t\\t\\tData in GiB\\n\\t\\t\\t-----------\")\n",
    "print(gtotal_df[col_list].sum().divide(1024*1024*1024))\n",
    "print()\n",
    "print('#'*20+\"\\nPossible Filesystems\\n\"+'#'*20)\n",
    "pprint.pprint(report.mounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Count Sumamry\n",
    "- how many files are you using? Too many?\n",
    "- Consider most file systems support between 10k - 50k creates per second\n",
    "- How much data is in each file? Is that sufficient to offset the create/open cost?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {}\n",
    "unit = 1024*1024\n",
    "t = total_df.groupby('rank').sum()\n",
    "c = total_df.shape[0]\n",
    "if c > 0:\n",
    "    wkey = []\n",
    "    rkey = []\n",
    "    if 'POSIX_MAX_BYTE_WRITTEN' in t:\n",
    "        wkey.append('POSIX_MAX_BYTE_WRITTEN')\n",
    "        rkey.append('POSIX_MAX_BYTE_READ')\n",
    "    if 'STDIO_MAX_BYTE_WRITTEN' in t:\n",
    "        wkey.append('STDIO_MAX_BYTE_WRITTEN')\n",
    "        rkey.append('STDIO_MAX_BYTE_READ')\n",
    "    w = t[wkey].max().max() / unit\n",
    "    r = t[rkey].max().max() / unit\n",
    "    s = t[wkey+rkey].sum().sum() / unit\n",
    "    table['total'] = { 'number': c, 'avg': s/c, 'max': max(w,r) }\n",
    "\n",
    "def file_count(condition, key):\n",
    "    t = total_df.query(condition).groupby('rank').sum()\n",
    "    c = t.shape[0]\n",
    "    if c > 0:\n",
    "        wkey = []\n",
    "        rkey = []\n",
    "        if 'POSIX_MAX_BYTE_WRITTEN' in t:\n",
    "            wkey.append('POSIX_MAX_BYTE_WRITTEN')\n",
    "            rkey.append('POSIX_MAX_BYTE_READ')\n",
    "        if 'STDIO_MAX_BYTE_WRITTEN' in t:\n",
    "            wkey.append('STDIO_MAX_BYTE_WRITTEN')\n",
    "            rkey.append('STDIO_MAX_BYTE_READ')\n",
    "        w = t[wkey].max().max() / unit\n",
    "        r = t[rkey].max().max() / unit\n",
    "        s = t[wkey+rkey].sum().sum() / unit\n",
    "        table[key] = { 'number': c, 'avg': s/c, 'max': max(w,r) }\n",
    "\n",
    "condition = \"\"\n",
    "if 'POSIX' in report.modules:\n",
    "    condition += \"(POSIX_READS > 0 & POSIX_WRITES <= 0)\"\n",
    "if 'STDIO' in report.modules:\n",
    "    condition += '|' if condition else \"\"\n",
    "    condition += \"(STDIO_READS > 0 & STDIO_WRITES <= 0)\"\n",
    "file_count(condition, 'read-only')\n",
    "\n",
    "condition = \"\"\n",
    "if 'POSIX' in report.modules:\n",
    "    condition += \"(POSIX_WRITES > 0 & POSIX_READS <= 0)\"\n",
    "if 'STDIO' in report.modules:\n",
    "    condition += '|' if condition else \"\"\n",
    "    condition += \"(STDIO_WRITES > 0 & STDIO_READS <= 0)\"\n",
    "file_count(condition, 'write-only')\n",
    "\n",
    "condition = \"\"\n",
    "if 'POSIX' in report.modules:\n",
    "    condition += \"(POSIX_WRITES > 0 & POSIX_READS > 0)\"\n",
    "if 'STDIO' in report.modules:\n",
    "    condition += '|' if condition else \"\"\n",
    "    condition += \"(STDIO_WRITES > 0 & STDIO_READS > 0)\"\n",
    "file_count(condition, 'read-write')\n",
    "\n",
    "print('#'*40+\"\\nFile Count Summary - Values in MiB\\n\"+'#'*40)\n",
    "pprint.pprint(table, width=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O Operations\n",
    "Next we can look at total operations count.\n",
    "\n",
    "There isn't an absolute good or bad value for these counters. However, counts into the millions and billions\n",
    "may indicate the IOP load is likely higher than desired. Look at increasing the size of I/Os to reduce the number\n",
    "of operations.\n",
    "\n",
    "High number of seeks, stats, flushes can also indicate areas that are degrading I/O performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = []\n",
    "posix_list = ['POSIX_OPENS', 'POSIX_WRITES', 'POSIX_READS', 'POSIX_STATS', 'POSIX_SEEKS', \n",
    "            'POSIX_MMAPS', 'POSIX_FSYNCS']\n",
    "mpiio_list = ['MPIIO_INDEP_OPENS', 'MPIIO_COLL_OPENS', 'MPIIO_INDEP_WRITES', 'MPIIO_COLL_WRITES',\n",
    "              'MPIIO_INDEP_READS', 'MPIIO_COLL_READS', 'MPIIO_SYNCS']\n",
    "stdio_list = ['STDIO_OPENS', 'STDIO_WRITES', 'STDIO_READS', 'STDIO_SEEKS', 'STDIO_FLUSHES']\n",
    "if 'POSIX' in report.modules:\n",
    "    col_list += posix_list\n",
    "if 'MPI-IO' in report.modules:\n",
    "    col_list += mpiio_list\n",
    "if 'STDIO' in report.modules:\n",
    "    col_list += stdio_list\n",
    "\n",
    "series = total_df[col_list].sum(axis=0)\n",
    "#print(series)\n",
    "series.plot.bar(title='Total I/O Operations', ylabel=\"Count of Operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O Access\n",
    "- small i/o is usaually inieffcient unless read/write buffering done by FS\n",
    "- larger sizes are usuaslly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'POSIX' in report.modules:\n",
    "    col_list = ['POSIX_SIZE_READ_0_100',    'POSIX_SIZE_WRITE_0_100',\n",
    "                'POSIX_SIZE_READ_100_1K',   'POSIX_SIZE_WRITE_100_1K',\n",
    "                'POSIX_SIZE_READ_1K_10K',   'POSIX_SIZE_WRITE_1K_10K',\n",
    "                'POSIX_SIZE_READ_10K_100K', 'POSIX_SIZE_WRITE_10K_100K',\n",
    "                'POSIX_SIZE_READ_100K_1M',  'POSIX_SIZE_WRITE_100K_1M',\n",
    "                'POSIX_SIZE_READ_1M_4M',    'POSIX_SIZE_WRITE_1M_4M',\n",
    "                'POSIX_SIZE_READ_4M_10M',   'POSIX_SIZE_WRITE_4M_10M',\n",
    "                'POSIX_SIZE_READ_10M_100M', 'POSIX_SIZE_WRITE_10M_100M',\n",
    "                'POSIX_SIZE_READ_100M_1G',  'POSIX_SIZE_WRITE_100M_1G',\n",
    "                'POSIX_SIZE_READ_1G_PLUS',  'POSIX_SIZE_WRITE_1G_PLUS']\n",
    "    series = total_df[col_list].sum(axis=0)\n",
    "    series.plot.bar(title=\"POSIX Access Sizes\", ylabel=\"Count (Total, All Procs)\",color=['m','g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'MPI-IO' in report.modules:\n",
    "    col_list = ['MPIIO_SIZE_READ_AGG_0_100',    'MPIIO_SIZE_WRITE_AGG_0_100',\n",
    "                'MPIIO_SIZE_READ_AGG_100_1K',   'MPIIO_SIZE_WRITE_AGG_100_1K',\n",
    "                'MPIIO_SIZE_READ_AGG_1K_10K',   'MPIIO_SIZE_WRITE_AGG_1K_10K',\n",
    "                'MPIIO_SIZE_READ_AGG_10K_100K', 'MPIIO_SIZE_WRITE_AGG_10K_100K',\n",
    "                'MPIIO_SIZE_READ_AGG_100K_1M',  'MPIIO_SIZE_WRITE_AGG_100K_1M',\n",
    "                'MPIIO_SIZE_READ_AGG_1M_4M',    'MPIIO_SIZE_WRITE_AGG_1M_4M',\n",
    "                'MPIIO_SIZE_READ_AGG_4M_10M',   'MPIIO_SIZE_WRITE_AGG_4M_10M',\n",
    "                'MPIIO_SIZE_READ_AGG_10M_100M', 'MPIIO_SIZE_WRITE_AGG_10M_100M',\n",
    "                'MPIIO_SIZE_READ_AGG_100M_1G',  'MPIIO_SIZE_WRITE_AGG_100M_1G',\n",
    "                'MPIIO_SIZE_READ_AGG_1G_PLUS',  'MPIIO_SIZE_WRITE_AGG_1G_PLUS']\n",
    "    series = total_df[col_list].sum(axis=0)\n",
    "    series.plot.bar(title=\"MPI-IO Access Sizes\", ylabel=\"Count (Total, All Procs)\",color=['m','g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
